# ---------------
# Mock providers
# ---------------
mock_provider "aws" {
  # This is used because the mocked data is a random string instead of JSON, causing downstream dependencies to fail.
  # This block overrides the "json" output of ALL aws_iam_policy_document data blocks to use a JSON encoded string.
  mock_data "aws_iam_policy_document" {
    defaults = {
      json = "{\"some_fake\":\"json\"}"
    }
  }
  # This is used to return valid zone names for the us-west-2 zone instead of the random strings that Terraform will
  # generate for mocked tests. Not using this will cause the data block to create an empty list of strings.
  mock_data "aws_availability_zones" {
    defaults = {
      names = ["us-gov-west-1a", "us-gov-west-1b", "us-gov-west-1c"]
    }
  }
}

# A mocked databricks provider is added here so that the alias requirement can be met
mock_provider "databricks" {
  alias = "mws"

  # This is used to return valid JSON for the data types of the assume role policy.
  mock_data "databricks_aws_assume_role_policy" {
    defaults = {
      json = "{\"some_fake\":\"json\"}"
    }
  }

}
# --------------

# ---------------
# Variables
# ---------------
# The variables block below provides variable values for the configuration in this directory (tf/aws/variables.tf).
# Note that the below values were generated by AI, and are not real values.

variables {
  availability_zones                       = ["us-gov-west-1a", "us-gov-west-1b", "us-gov-west-1c"]
  aws_account_id                           = "123456789012"
  client_id                                = "your-client-id"
  client_secret                            = "your-client-secret"
  cmk_admin_arn                            = "arn:aws-us-gov:iam::123456789012:role/CMKAdminRole"
  compliance_security_profile_egress_ports = true
  custom_private_subnet_ids                = ["subnet-0abcd1234efgh5678", "subnet-1abcd1234efgh5678"]
  custom_relay_vpce_id                     = "vpce-0abcd1234efgh5678"
  custom_sg_id                             = "sg-0abcd1234efgh5678"
  custom_vpc_id                            = "vpc-0abcd1234efgh5678"
  custom_workspace_vpce_id                 = "vpce-1abcd1234efgh5678"
  databricks_account_id                    = "databricks-account-id"
  deployment_name                          = "test-deployment"
  enable_admin_configs_boolean             = true
  firewall_allow_list                      = ["192.168.0.1/32", "10.0.0.0/24"]
  firewall_subnets_cidr                    = ["10.1.0.0/16", "10.2.0.0/16"]
  ip_addresses                             = ["203.0.113.1", "198.51.100.2"]
  metastore_exists                         = false
  network_configuration                    = "isolated"
  private_subnets_cidr                     = ["10.0.3.0/24", "10.0.4.0/24"]
  privatelink_subnets_cidr                 = ["10.0.5.0/24", "10.0.6.0/24"]
  public_subnets_cidr                      = ["10.0.7.0/24", "10.0.8.0/24"]
  read_only_data_bucket                    = "s3://my-read-only-data-bucket"
  read_only_external_location_admin        = "admin-user@example.com"
  region                                   = "us-gov-west-1"
  region_name                              = "US Gov West (Pendleton)"
  resource_prefix                          = "my-resource-prefix"
  sg_egress_ports                          = ["443", "80"]
  admin_user                               = "workspace-admin-user@example.com"
  vpc_cidr_range                           = "10.0.0.0/16"
  databricks_gov_shard                     = "civilian"
  region_bucket_name                       = "pendleton"
}

# -------
# Tests
# -------
# This runs a plan command on the module directly
run "plan_test" {
  command = plan
}