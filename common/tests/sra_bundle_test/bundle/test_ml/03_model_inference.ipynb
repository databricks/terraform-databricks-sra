{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbd5c09",
   "metadata": {},
   "source": [
    "# NYC Taxi Fare Model Inference\n",
    "\n",
    "This notebook demonstrates how to load the trained taxi fare prediction model from Unity Catalog and run inference on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup widgets for model configuration\n",
    "dbutils.widgets.text(\"model_name\", \"mlflow3_demo\", \"Model Name\")\n",
    "dbutils.widgets.text(\"model_alias\", \"challenger\", \"Model Alias\")\n",
    "dbutils.widgets.text(\"catalog\", \"main\", \"Catalog\")\n",
    "dbutils.widgets.text(\"schema\", \"default\", \"Schema\") \n",
    "dbutils.widgets.text(\"features_table\", \"main.default.features\", \"Source Data Table (for batch inference)\")\n",
    "dbutils.widgets.text(\"predictions_table\", \"main.default.predictions\", \"Predictions Table Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179dd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get widget values\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "model_name = dbutils.widgets.get(\"model_name\")\n",
    "model_alias = dbutils.widgets.get(\"model_alias\")\n",
    "features_table = dbutils.widgets.get(\"features_table\")\n",
    "predictions_table = dbutils.widgets.get(\"predictions_table\")\n",
    "\n",
    "# Construct model URI\n",
    "full_model_name = f\"{catalog}.{schema}.{model_name}\"\n",
    "model_uri = f\"models:/{full_model_name}@{model_alias}\"\n",
    "\n",
    "print(f\"Model URI: {model_uri}\")\n",
    "print(f\"Source table for batch inference: {features_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bacf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set MLflow registry URI to Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "print(f\"Registry URI: {mlflow.get_registry_uri()}\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model from Unity Catalog\n",
    "print(f\"Loading model from Unity Catalog: {model_uri}\")\n",
    "\n",
    "try:\n",
    "    # Load the model\n",
    "    loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "    print(f\"Successfully loaded model: {full_model_name} (alias: {model_alias})\")\n",
    "    \n",
    "    # Get model information\n",
    "    model_info = mlflow.models.get_model_info(model_uri)\n",
    "    print(f\"\\nModel Information:\")\n",
    "    print(f\"  - Run ID: {model_info.run_id}\")\n",
    "    print(f\"  - Model UUID: {model_info.model_uuid}\")\n",
    "    print(f\"  - MLflow Version: {model_info.mlflow_version}\")\n",
    "    \n",
    "    # Display model signature if available\n",
    "    if model_info.signature:\n",
    "        print(f\"\\nModel Signature:\")\n",
    "        print(f\"  - Input Schema: {model_info.signature.inputs}\")\n",
    "        print(f\"  - Output Schema: {model_info.signature.outputs}\")\n",
    "    \n",
    "    # Check if this is the expected model type\n",
    "    print(f\"\\nModel Type: {type(loaded_model).__name__}\")\n",
    "    print(f\"Model ready for inference! ğŸ¯\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {str(e)}\")\n",
    "    print(\"Make sure the model exists in Unity Catalog and you have access permissions\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7706333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for single prediction inference\n",
    "print(\"ğŸ§ª Creating sample data for inference...\")\n",
    "\n",
    "# The model expects these features (from training):\n",
    "# ['trip_distance', 'pickup_hour', 'pickup_day_of_week', 'pickup_month', 'trip_duration_minutes']\n",
    "\n",
    "# Create sample trip scenarios\n",
    "sample_trips = [\n",
    "    {\n",
    "        \"trip_distance\": 2.5,\n",
    "        \"pickup_hour\": 14,  # 2 PM\n",
    "        \"pickup_day_of_week\": 2,  # Monday (1=Sunday, 2=Monday, etc.)\n",
    "        \"pickup_month\": 6,  # June\n",
    "        \"trip_duration_minutes\": 15\n",
    "    },\n",
    "    {\n",
    "        \"trip_distance\": 0.8,\n",
    "        \"pickup_hour\": 8,  # 8 AM rush hour\n",
    "        \"pickup_day_of_week\": 3,  # Tuesday\n",
    "        \"pickup_month\": 12,  # December\n",
    "        \"trip_duration_minutes\": 8\n",
    "    },\n",
    "    {\n",
    "        \"trip_distance\": 15.2,\n",
    "        \"pickup_hour\": 22,  # 10 PM\n",
    "        \"pickup_day_of_week\": 7,  # Saturday\n",
    "        \"pickup_month\": 7,  # July\n",
    "        \"trip_duration_minutes\": 45\n",
    "    },\n",
    "    {\n",
    "        \"trip_distance\": 5.1,\n",
    "        \"pickup_hour\": 18,  # 6 PM\n",
    "        \"pickup_day_of_week\": 6,  # Friday\n",
    "        \"pickup_month\": 3,  # March\n",
    "        \"trip_duration_minutes\": 22\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_df = pd.DataFrame(sample_trips)\n",
    "\n",
    "print(f\"Created {len(sample_trips)} sample trips:\")\n",
    "print(sample_df)\n",
    "print(f\"\\nFeature columns: {list(sample_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b7b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions on sample data\n",
    "print(\"ğŸ”® Running predictions on sample trips...\")\n",
    "\n",
    "try:\n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(sample_df)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = sample_df.copy()\n",
    "    results_df['predicted_fare'] = predictions\n",
    "    results_df['predicted_fare'] = results_df['predicted_fare'].round(2)\n",
    "    \n",
    "    print(f\"Predictions completed!\")\n",
    "    print(f\"\\nPrediction Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display results with interpretations\n",
    "    for idx, row in results_df.iterrows():\n",
    "        trip_desc = f\"Trip {idx+1}: {row['trip_distance']} miles\"\n",
    "        time_desc = f\"at {row['pickup_hour']}:00 on \"\n",
    "        \n",
    "        # Day of week mapping\n",
    "        days = {1: \"Sunday\", 2: \"Monday\", 3: \"Tuesday\", 4: \"Wednesday\", \n",
    "                5: \"Thursday\", 6: \"Friday\", 7: \"Saturday\"}\n",
    "        day_name = days.get(row['pickup_day_of_week'], \"Unknown\")\n",
    "        \n",
    "        # Month mapping\n",
    "        months = {1: \"Jan\", 2: \"Feb\", 3: \"Mar\", 4: \"Apr\", 5: \"May\", 6: \"Jun\",\n",
    "                 7: \"Jul\", 8: \"Aug\", 9: \"Sep\", 10: \"Oct\", 11: \"Nov\", 12: \"Dec\"}\n",
    "        month_name = months.get(row['pickup_month'], \"Unknown\")\n",
    "        \n",
    "        print(f\"{trip_desc} {time_desc}{day_name} in {month_name}\")\n",
    "        print(f\"  Duration: {row['trip_duration_minutes']} minutes\")\n",
    "        print(f\"  Predicted Fare: ${row['predicted_fare']}\")\n",
    "        print()\n",
    "    \n",
    "    # Display as table\n",
    "    print(\"Summary Table:\")\n",
    "    display(results_df)\n",
    "    \n",
    "    # Some basic analysis\n",
    "    avg_fare = results_df['predicted_fare'].mean()\n",
    "    min_fare = results_df['predicted_fare'].min()\n",
    "    max_fare = results_df['predicted_fare'].max()\n",
    "    \n",
    "    print(f\"Prediction Statistics:\")\n",
    "    print(f\"  - Average predicted fare: ${avg_fare:.2f}\")\n",
    "    print(f\"  - Minimum predicted fare: ${min_fare:.2f}\")\n",
    "    print(f\"  - Maximum predicted fare: ${max_fare:.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single trip prediction example\n",
    "print(\"Single Trip Prediction Example\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Example: A 3.2-mile trip at 3 PM on a Friday in September, taking 18 minutes\n",
    "single_trip = {\n",
    "    \"trip_distance\": 3.2,\n",
    "    \"pickup_hour\": 15,  # 3 PM\n",
    "    \"pickup_day_of_week\": 6,  # Friday\n",
    "    \"pickup_month\": 9,  # September\n",
    "    \"trip_duration_minutes\": 18\n",
    "}\n",
    "\n",
    "# Convert to DataFrame (model expects DataFrame input)\n",
    "single_trip_df = pd.DataFrame([single_trip])\n",
    "\n",
    "# Make prediction\n",
    "single_prediction = loaded_model.predict(single_trip_df)[0]\n",
    "\n",
    "print(f\"Trip Details:\")\n",
    "print(f\"  - Distance: {single_trip['trip_distance']} miles\")\n",
    "print(f\"  - Time: 3:00 PM on Friday\")\n",
    "print(f\"  - Month: September\")  \n",
    "print(f\"  - Duration: {single_trip['trip_duration_minutes']} minutes\")\n",
    "print(f\"\\nPredicted Fare: ${single_prediction:.2f}\")\n",
    "\n",
    "# Calculate fare per mile\n",
    "fare_per_mile = single_prediction / single_trip['trip_distance']\n",
    "print(f\"Fare per mile: ${fare_per_mile:.2f}\")\n",
    "\n",
    "# Show the input format for reference\n",
    "print(f\"\\nInput format for API calls:\")\n",
    "print(f\"Input DataFrame shape: {single_trip_df.shape}\")\n",
    "print(f\"Required columns: {list(single_trip_df.columns)}\")\n",
    "display(single_trip_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03353990",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Batch Inference on Real Data\n",
    "\n",
    "This section demonstrates batch inference using actual data from Unity Catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch inference on real data from Unity Catalog\n",
    "print(f\"Loading data for batch inference from: {features_table}\")\n",
    "\n",
    "try:\n",
    "    # Load data from Unity Catalog\n",
    "    batch_df = spark.table(features_table)\n",
    "    \n",
    "    print(f\"Loaded {batch_df.count():,} rows from {features_table}\")\n",
    "    \n",
    "    # Prepare features (same feature engineering as training)\n",
    "    batch_features = batch_df.select(\n",
    "        # Original columns for reference\n",
    "        F.col(\"tpep_pickup_datetime\"),\n",
    "        F.col(\"tpep_dropoff_datetime\"), \n",
    "        F.col(\"fare_amount\").alias(\"actual_fare\"),\n",
    "        \n",
    "        # Features for prediction\n",
    "        F.col(\"trip_distance\"),\n",
    "        F.hour(F.col(\"tpep_pickup_datetime\")).alias(\"pickup_hour\"),\n",
    "        F.dayofweek(F.col(\"tpep_pickup_datetime\")).alias(\"pickup_day_of_week\"),\n",
    "        F.month(F.col(\"tpep_pickup_datetime\")).alias(\"pickup_month\"),\n",
    "        ((F.unix_timestamp(F.col(\"tpep_dropoff_datetime\")) - \n",
    "          F.unix_timestamp(F.col(\"tpep_pickup_datetime\"))) / 60).alias(\"trip_duration_minutes\")\n",
    "    ).filter(\n",
    "        # Apply same filters as training\n",
    "        (F.col(\"fare_amount\") > 0) & \n",
    "        (F.col(\"fare_amount\") < 1000) &\n",
    "        (F.col(\"trip_distance\") > 0) & \n",
    "        (F.col(\"trip_distance\") < 100) &\n",
    "        (F.col(\"trip_duration_minutes\") > 0) &\n",
    "        (F.col(\"trip_duration_minutes\") < 300)\n",
    "    ).limit(1000)  # Limit for demo purposes\n",
    "    \n",
    "    print(f\"After filtering: {batch_features.count():,} rows ready for inference\")\n",
    "    print(\"\\nSample of prepared data:\")\n",
    "    display(batch_features.limit(5))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading batch data: {str(e)}\")\n",
    "    print(\"Make sure the source table exists and contains the expected columns\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch predictions\n",
    "print(\"Running batch inference...\")\n",
    "\n",
    "# Convert to Pandas for model prediction (sample for performance)\n",
    "batch_sample = batch_features.sample(fraction=0.1, seed=42).toPandas()\n",
    "\n",
    "print(f\"Running inference on {len(batch_sample):,} samples...\")\n",
    "\n",
    "# Select feature columns for prediction\n",
    "feature_columns = ['trip_distance', 'pickup_hour', 'pickup_day_of_week', \n",
    "                  'pickup_month', 'trip_duration_minutes']\n",
    "\n",
    "X_batch = batch_sample[feature_columns]\n",
    "\n",
    "# Make batch predictions\n",
    "batch_predictions = loaded_model.predict(X_batch)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "batch_sample['predicted_fare'] = batch_predictions\n",
    "batch_sample['predicted_fare'] = batch_sample['predicted_fare'].round(2)\n",
    "\n",
    "# Calculate prediction vs actual differences\n",
    "batch_sample['fare_difference'] = (batch_sample['predicted_fare'] - batch_sample['actual_fare']).round(2)\n",
    "batch_sample['absolute_error'] = abs(batch_sample['fare_difference']).round(2)\n",
    "batch_sample['percentage_error'] = (abs(batch_sample['fare_difference']) / batch_sample['actual_fare'] * 100).round(1)\n",
    "\n",
    "print(\"Batch predictions completed!\")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nBatch Inference Results (sample of {len(batch_sample):,} trips):\")\n",
    "result_columns = ['trip_distance', 'pickup_hour', 'trip_duration_minutes', \n",
    "                 'actual_fare', 'predicted_fare', 'fare_difference', 'percentage_error']\n",
    "display(batch_sample[result_columns].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model version by alias using MLflow API\n",
    "client = MlflowClient()\n",
    "model_version = client.get_model_version_by_alias(full_model_name, model_alias).version\n",
    "print(f\"Model version for alias '{model_alias}': {model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata before saving predictions\n",
    "print(\"Adding prediction metadata...\")\n",
    "\n",
    "# Add prediction metadata columns\n",
    "current_timestamp = datetime.now()\n",
    "\n",
    "batch_sample['prediction_timestamp'] = current_timestamp\n",
    "batch_sample['model_id'] = model_version\n",
    "batch_sample['model_name'] = full_model_name\n",
    "batch_sample['model_run_id'] = model_info.run_id\n",
    "\n",
    "print(f\"Metadata added:\")\n",
    "print(f\"  - Prediction timestamp: {current_timestamp}\")\n",
    "print(f\"  - Model version: {model_version}\")\n",
    "print(f\"  - Model name: {full_model_name}\")\n",
    "print(f\"  - Model run ID: {model_info.run_id}\")\n",
    "\n",
    "# Show updated columns\n",
    "print(f\"\\nUpdated columns ({len(batch_sample.columns)} total):\")\n",
    "print(f\"New metadata columns: prediction_timestamp, model_id (model_version), model_name, model_run_id\")\n",
    "print(f\"All columns: {list(batch_sample.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze batch inference performance\n",
    "print(\"Batch Inference Performance Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = batch_sample['absolute_error'].mean()\n",
    "rmse = np.sqrt((batch_sample['fare_difference'] ** 2).mean())\n",
    "mean_percentage_error = batch_sample['percentage_error'].mean()\n",
    "median_percentage_error = batch_sample['percentage_error'].median()\n",
    "\n",
    "print(f\"Performance Metrics:\")\n",
    "print(f\"  - Mean Absolute Error (MAE): ${mae:.2f}\")\n",
    "print(f\"  - Root Mean Square Error (RMSE): ${rmse:.2f}\")\n",
    "print(f\"  - Mean Percentage Error: {mean_percentage_error:.1f}%\")\n",
    "print(f\"  - Median Percentage Error: {median_percentage_error:.1f}%\")\n",
    "\n",
    "# Accuracy within ranges\n",
    "within_1_dollar = (batch_sample['absolute_error'] <= 1.0).mean() * 100\n",
    "within_2_dollars = (batch_sample['absolute_error'] <= 2.0).mean() * 100\n",
    "within_5_dollars = (batch_sample['absolute_error'] <= 5.0).mean() * 100\n",
    "\n",
    "print(f\"\\nAccuracy Ranges:\")\n",
    "print(f\"  - Predictions within $1.00: {within_1_dollar:.1f}%\")\n",
    "print(f\"  - Predictions within $2.00: {within_2_dollars:.1f}%\")\n",
    "print(f\"  - Predictions within $5.00: {within_5_dollars:.1f}%\")\n",
    "\n",
    "# Show distribution of errors\n",
    "print(f\"\\nError Distribution:\")\n",
    "print(batch_sample['absolute_error'].describe())\n",
    "\n",
    "# Find best and worst predictions\n",
    "best_predictions = batch_sample.nsmallest(3, 'absolute_error')[['trip_distance', 'actual_fare', 'predicted_fare', 'absolute_error']]\n",
    "worst_predictions = batch_sample.nlargest(3, 'absolute_error')[['trip_distance', 'actual_fare', 'predicted_fare', 'absolute_error']]\n",
    "\n",
    "print(f\"\\nBest Predictions (lowest error):\")\n",
    "display(best_predictions)\n",
    "\n",
    "print(f\"\\nWorst Predictions (highest error):\")\n",
    "display(worst_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbfe30f",
   "metadata": {},
   "source": [
    "## Prediction Table\n",
    "\n",
    "The prediction table includes these important metadata columns:\n",
    "\n",
    "- **`prediction_timestamp`**: When the prediction was made\n",
    "- **`model_id`**: Version of the model used (e.g., \"latest\", \"1\", \"2\")  \n",
    "- **`model_name`**: Full Unity Catalog model name\n",
    "- **`model_run_id`**: MLflow run ID for complete traceability (though this isn't needed by the quality monitor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions back to Unity Catalog\n",
    "print(\"Save predictions to Unity Catalog\")\n",
    "\n",
    "try:\n",
    "    # Convert back to Spark DataFrame and save\n",
    "    predictions_spark_df = spark.createDataFrame(batch_sample)\n",
    "    \n",
    "    # Show what we would save\n",
    "    print(f\"Would save {batch_sample.shape[0]:,} predictions to: {predictions_table}\")\n",
    "    print(f\"Columns to save: {list(batch_sample.columns)}\")\n",
    "    \n",
    "    # Check if table exists to determine append vs create\n",
    "    try:\n",
    "        # Try to describe the table to see if it exists\n",
    "        spark.sql(f\"DESCRIBE TABLE {predictions_table}\")\n",
    "        write_mode = \"append\"\n",
    "        action_verb = \"appended to\"\n",
    "        print(f\"Table {predictions_table} exists - appending new predictions...\")\n",
    "        \n",
    "        # Check current row count before appending\n",
    "        current_count = spark.table(predictions_table).count()\n",
    "        print(f\"Current table has {current_count:,} rows\")\n",
    "        \n",
    "    except Exception:\n",
    "        # Table doesn't exist, create it\n",
    "        write_mode = \"overwrite\"\n",
    "        action_verb = \"saved to new table\"\n",
    "        print(f\"Creating new predictions table: {predictions_table}\")\n",
    "    \n",
    "    # Save with appropriate mode (append for existing table, overwrite for new)\n",
    "    predictions_spark_df.write.mode(write_mode).saveAsTable(predictions_table)\n",
    "    print(f\"Predictions {action_verb} {predictions_table}\")\n",
    "    \n",
    "    # Show final row count\n",
    "    final_count = spark.table(predictions_table).count()\n",
    "    print(f\"Table now contains {final_count:,} total predictions\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error saving predictions: {str(e)}\")\n",
    "\n",
    "print(f\"\\nInference Summary:\")\n",
    "print(f\"  - Model loaded from: {model_uri}\")\n",
    "print(f\"  - Processed {len(batch_sample):,} trips\")\n",
    "print(f\"  - Average prediction error: ${mae:.2f}\")\n",
    "print(f\"  - Model ready for production use!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
